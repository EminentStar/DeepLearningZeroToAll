{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 3.98538 [ 0.07587355]\n",
      "1 1.13362 [ 0.50713253]\n",
      "2 0.322452 [ 0.73713732]\n",
      "3 0.0917195 [ 0.8598066]\n",
      "4 0.0260891 [ 0.92523021]\n",
      "5 0.00742091 [ 0.96012276]\n",
      "6 0.00211083 [ 0.97873217]\n",
      "7 0.000600413 [ 0.98865718]\n",
      "8 0.000170783 [ 0.99395049]\n",
      "9 4.85792e-05 [ 0.9967736]\n",
      "10 1.38177e-05 [ 0.99827927]\n",
      "11 3.93053e-06 [ 0.99908227]\n",
      "12 1.11806e-06 [ 0.99951053]\n",
      "13 3.18065e-07 [ 0.99973893]\n",
      "14 9.04717e-08 [ 0.99986076]\n",
      "15 2.5722e-08 [ 0.99992573]\n",
      "16 7.33652e-09 [ 0.99996036]\n",
      "17 2.08689e-09 [ 0.99997884]\n",
      "18 5.93574e-10 [ 0.99998873]\n",
      "19 1.69845e-10 [ 0.99999398]\n",
      "20 4.75827e-11 [ 0.99999678]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n실행을 시켜보면\\n젤앞이 step, 두번째가 cost, 마지막이 W값이다.\\n\\n처음에 시작하면 W가 랜덤하니 cost가 상당한데,\\nstep을 진행할수록 cost가 작아지고, 우리가 예상한데로 W가 1에 가깝게 된다.\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lab 3\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x_data = [1, 2, 3]\n",
    "y_data = [1, 2, 3]\n",
    "\n",
    "# W를 텐서플로 배리어블로 선언하고 랜덤값을 주고\n",
    "W = tf.Variable(tf.random_normal([1]), name='weight')\n",
    "# X, Y 플레이스홀더로 두고요.\n",
    "X = tf.placeholder(tf.float32)\n",
    "Y = tf.placeholder(tf.float32)\n",
    "\n",
    "# Our hypothesis for linear model X * W\n",
    "hypothesis = X * W\n",
    "\n",
    "# cost/loss function\n",
    "cost = tf.reduce_sum(tf.square(hypothesis - Y))\n",
    "\n",
    "# Minimize: Gradient Descent using deriative: W-= learning_rate derivative\n",
    "\n",
    "# Gradient descent\n",
    "# 미분값을 사용하는데 이유는, 미분이란게 어떤 한 점에서의 기울기를 나타내는 거죠.\n",
    "# 그 기울기를 보고,, 기울기가 플러스(+)가 되면, W는 안쪽(-)로 가야한다. (vice versa)\n",
    "# 그래서 식을 이야기 할 때, 현재의 W에다가 cost함수의 기울기(미분한값)를 빼주면 된다.\n",
    "# 이걸 tensorflow로 어떻게 구현할까?\n",
    "\"\"\"\n",
    "learning_rate = 0.1 #알파.\n",
    "gradient = tf.reduce_mean((W * X - Y) * X)\n",
    "descent = W - learning_rate * gradient # 새로나온 W 값\n",
    "update = W.assign(descent)\n",
    "\n",
    "텐서플로를 사용하면,,,,\n",
    "\n",
    "우리가 매번 미분값이란 것이 여기선 쉽게 주어졌지만,\n",
    "이것이 굉장히 복잡히질 수잇는데 이게 일일히 미분 할 필요 없이 \n",
    "optimizer를 선언하고 이 optimizer를 통해 cost를 미니마이즈해! 하면 텐서플로우가 자동으로 해줍니다.\n",
    "우리가 미분하지 않고도 똑같이 된다.\n",
    "\n",
    "# Launch the graph in a session\n",
    "sess =tf.Session() # 그래프이기에 세션을 열고\n",
    "\n",
    "# Initializes global variables in the graph.\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for step in range(21):\n",
    "    sess.run(update, feed_dict={X: x_data, Y: y_data}) # update란 걸 실행시킨다.\n",
    "    # x_data, y_data를 던져주면서 실행.\n",
    "    # 정말 잘 업데이트가 되는지 cost와 W값을 한번 보는겁니다.\n",
    "    print(step, sess.run(cost, feed_dict={X: x_data, Y: y_data}), sess.run(W))\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "hypothesis = X * W\n",
    "\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "\n",
    "learning_rate = 0.1\n",
    "gradient = tf.reduce_mean((W * X - Y) * X)\n",
    "descent = W - learning_rate * gradient\n",
    "update = W.assign(descent)\n",
    "\n",
    "# Launch the graph in a session\n",
    "sess = tf.Session()\n",
    "# Inintializes global variables in the graph.\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in range(21):\n",
    "    sess.run(update, feed_dict={X:x_data, Y: y_data})\n",
    "    print(step, sess.run(cost, feed_dict={X: x_data, Y: y_data}), sess.run(W))\n",
    "    \n",
    "\n",
    "\"\"\"\n",
    "실행을 시켜보면\n",
    "젤앞이 step, 두번째가 cost, 마지막이 W값이다.\n",
    "\n",
    "처음에 시작하면 W가 랜덤하니 cost가 상당한데,\n",
    "step을 진행할수록 cost가 작아지고, 우리가 예상한데로 W가 1에 가깝게 된다.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
